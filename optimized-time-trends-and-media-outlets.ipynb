{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os \nos.listdir('/kaggle/input') \n\nembeddings_path = \"/kaggle/input/embeddings\"\nprint(os.listdir(embeddings_path))\nimport pandas as pd\n\nspeeches_embeddings = pd.read_csv(f\"{embeddings_path}/speeches_with_embeddings.csv\")\nnews_embeddings = pd.read_csv(f\"{embeddings_path}/news_with_embeddings.csv\")\n\n# Display first few rows\nprint(\"News Data:\")\nprint(news_embeddings.head())\n\nprint(\"\\nSpeeches Data:\")\nprint(speeches_embeddings.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T13:35:58.265317Z","iopub.execute_input":"2025-03-25T13:35:58.265615Z","iopub.status.idle":"2025-03-25T13:41:54.073130Z","shell.execute_reply.started":"2025-03-25T13:35:58.265595Z","shell.execute_reply":"2025-03-25T13:41:54.072171Z"}},"outputs":[{"name":"stdout","text":"['speeches_with_embeddings.csv', 'speeches_embeddings_sentiment.csv', 'news_embeddings_sentiment.csv', 'news_with_embeddings.csv']\nNews Data:\n          Index                                               Link  \\\n0  1_01_12_2018  https://www.bbc.com/mundo/noticias-america-lat...   \n1  2_01_12_2018  https://politica.expansion.mx/presidencia/2018...   \n2  3_01_12_2018  https://oem.com.mx/elsoldemexico/mexico/en-don...   \n3  4_01_12_2018  https://politica.expansion.mx/presidencia/2018...   \n4  5_01_12_2018  https://www.eleconomista.com.mx/politica/Nicol...   \n\n                                              Domain  \\\n0  BBC\\nToma de protesta de AMLO: las 5 tradicion...   \n1  Expansión Política\\nAMLO rinde protesta y prom...   \n2  El Sol de México\\n¿Hay Ley Seca este 1 de dici...   \n3  Expansión Política\\nAMLO es un \"líder persiste...   \n4  El Economista\\nNicolás Maduro llega a Palacio ...   \n\n                                               Title        Date  \\\n0  Toma de protesta de AMLO: las 5 tradiciones qu...  2018-12-01   \n1        AMLO rinde protesta y promete no reelegirse  2018-12-01   \n2  ¿Hay Ley Seca este 1 de diciembre por cambio d...  2018-12-01   \n3  AMLO es un \"líder persistente\", dice la superc...  2018-12-01   \n4  Nicolás Maduro llega a Palacio Nacional; no as...  2018-12-01   \n\n                                             Content month_abbr  \\\n0  Fuente de la imagen, Getty Images Desde su cam...        dic   \n1  Síguenos en nuestras redes sociales: CIUDAD DE...        dic   \n2  Por la toma de posesión de Andrés Manuel López...        dic   \n3  Síguenos en nuestras redes sociales: CIUDAD DE...        dic   \n4  Lectura 3:00 min Nicolás Maduro arribó este sá...        dic   \n\n                                   processed_content  \\\n0  fuente imagen getty images campaña presidencia...   \n1  síguenos redes sociales ciudad méxico adnpolít...   \n2  toma posesión andrés manuel lópez obrador pres...   \n3  síguenos redes sociales ciudad méxico adnpolít...   \n4  lectura 3:00 min nicolás maduro   arribó sábad...   \n\n                                         news_chunks  \\\n0  fuente imagen getty images campaña presidencia...   \n1  síguenos redes sociales ciudad méxico adnpolít...   \n2  toma posesión andrés manuel lópez obrador pres...   \n3  síguenos redes sociales ciudad méxico adnpolít...   \n4  lectura 3:00 min nicolás maduro   arribó sábad...   \n\n                                     news_embeddings  \n0  [ 3.77706587e-01  9.13102329e-02 -1.38176888e-...  \n1  [ 2.61866331e-01  2.99132258e-01  1.76378831e-...  \n2  [ 5.06281674e-01  3.32773924e-02 -3.04715186e-...  \n3  [ 3.07641208e-01  7.52940923e-02 -5.62011823e-...  \n4  [ 3.04801702e-01  3.39728445e-01  3.13091815e-...  \n\nSpeeches Data:\n   Unnamed: 0  X  speech_id  \\\n0           1  1          1   \n1           1  1          1   \n2           1  1          1   \n3           1  1          1   \n4           1  1          1   \n\n                                               title  \\\n0  Versión estenográfica de la conferencia de pre...   \n1  Versión estenográfica de la conferencia de pre...   \n2  Versión estenográfica de la conferencia de pre...   \n3  Versión estenográfica de la conferencia de pre...   \n4  Versión estenográfica de la conferencia de pre...   \n\n                                                urls  \\\n0  https://lopezobrador.org.mx/2024/01/09/version...   \n1  https://lopezobrador.org.mx/2024/01/09/version...   \n2  https://lopezobrador.org.mx/2024/01/09/version...   \n3  https://lopezobrador.org.mx/2024/01/09/version...   \n4  https://lopezobrador.org.mx/2024/01/09/version...   \n\n                                             content        date  \\\n0  2024: Año de Felipe Carrillo Puerto, benemérit...  2024-01-09   \n1  2024: Año de Felipe Carrillo Puerto, benemérit...  2024-01-09   \n2  2024: Año de Felipe Carrillo Puerto, benemérit...  2024-01-09   \n3  2024: Año de Felipe Carrillo Puerto, benemérit...  2024-01-09   \n4  2024: Año de Felipe Carrillo Puerto, benemérit...  2024-01-09   \n\n                                       speech_chunks  \\\n0  2024: Año de Felipe Carrillo Puerto, benemérit...   \n1  Son los tres informes. Pero antes quiero dar a...   \n2  Entonces, ya voy a estar en TikTok y quiero in...   \n3  Entonces, ofrecer una disculpa y enviarle un a...   \n4  Me sumo al deseo de este año que sea lo mejor ...   \n\n                                   speech_embeddings  \n0  [-2.88460612e-01 -3.40319216e-01 -1.11393042e-...  \n1  [-2.88460612e-01 -3.40319216e-01 -1.11393042e-...  \n2  [-2.88460612e-01 -3.40319216e-01 -1.11393042e-...  \n3  [-2.88460612e-01 -3.40319216e-01 -1.11393042e-...  \n4  [-2.88460612e-01 -3.40319216e-01 -1.11393042e-...  \n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\n\n# Convert and verify date columns\nnews_embeddings['news_date'] = pd.to_datetime(news_embeddings['Date'])\nspeeches_embeddings['speech_date'] = pd.to_datetime(speeches_embeddings['date'])\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n#Temporal window calculation and expansion\ndef generate_temporal_pairs(news_df, speeches_df, window_days=3):\n    \"\"\"Generate news-speech pairs within a symmetric temporal window (-4 to +4 days)\"\"\"\n    pairs = []\n    chunk_size = 2000\n    news_chunks = np.array_split(news_df, len(news_df) // chunk_size + 1)\n    \n    for chunk in news_chunks:\n        for _, row in chunk.iterrows():\n            news_date = row['news_date']\n            start_date = news_date - pd.Timedelta(days=window_days) \n            end_date = news_date + pd.Timedelta(days=window_days)  \n            \n            mask = (speeches_df['speech_date'] >= start_date) & (speeches_df['speech_date'] <= end_date)\n            speech_ids = speeches_df[mask].index.tolist()\n            pairs.extend([(row.name, s_id) for s_id in speech_ids])\n    \n    return pd.DataFrame(pairs, columns=['news_id', 'speech_id'])\n\n\nalignment_df = generate_temporal_pairs(news_embeddings, speeches_embeddings)\n\n#optimized embeddings calculation\ndef load_embeddings_half(df, col_name):\n    embeddings = []\n    for i, row in df.iterrows():\n        if isinstance(row[col_name], str):\n            arr = np.fromstring(row[col_name].strip(\"[]\"), sep=\" \", dtype=np.float16)\n        else:\n            arr = np.array(row[col_name], dtype=np.float16)\n        embeddings.append(torch.tensor(arr, device=device).half())\n        if i % 1000 == 0: torch.cuda.empty_cache()\n    return torch.stack(embeddings)\n\nnews_tensor = load_embeddings_half(news_embeddings, 'news_embeddings')\nspeeches_tensor = load_embeddings_half(speeches_embeddings, 'speech_embeddings')\n\n#Batched cosine similarity computation\ndef compute_cosine_similarities(pairs_df, news_emb, speech_emb, batch_size=8192):\n    news_norm = F.normalize(news_emb, p=2, dim=1)\n    speech_norm = F.normalize(speech_emb, p=2, dim=1)\n    similarities = []\n    for i in range(0, len(pairs_df), batch_size):\n        batch = pairs_df.iloc[i:i+batch_size]\n        news_batch = news_norm[batch['news_id'].values]\n        speech_batch = speech_norm[batch['speech_id'].values]\n        similarities.append(F.cosine_similarity(news_batch, speech_batch).cpu().numpy())\n        del news_batch, speech_batch\n        torch.cuda.empty_cache()\n    return np.concatenate(similarities)\n\nalignment_df['cosine_similarity'] = compute_cosine_similarities(alignment_df, news_tensor, speeches_tensor)\n\n#include metadata to the embeddings to track temporal dependencies\ndef add_temporal_features(pairs_df, news_df, speeches_df):\n    pairs_df = pairs_df.merge(\n        news_df[['news_date']],\n        left_on='news_id',\n        right_index=True\n    ).merge(\n        speeches_df[['speech_date']],\n        left_on='speech_id',\n        right_index=True\n    )\n    pairs_df['days_diff'] = (pairs_df['news_date'] - pairs_df['speech_date']).dt.days\n    return pairs_df\n\nenriched_df = add_temporal_features(alignment_df, news_embeddings, speeches_embeddings)\n\n#Save data to avoid rerunning everything again \nenriched_df.to_parquet('news_speech_similarities.parquet', engine='pyarrow', compression='zstd')\nprint(\"Processing complete. Results saved with columns:\", enriched_df.columns.tolist())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T13:41:54.074138Z","iopub.execute_input":"2025-03-25T13:41:54.074406Z","iopub.status.idle":"2025-03-25T13:44:43.673828Z","shell.execute_reply.started":"2025-03-25T13:41:54.074375Z","shell.execute_reply":"2025-03-25T13:44:43.672908Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n  return bound(*args, **kwds)\n","output_type":"stream"},{"name":"stdout","text":"Processing complete. Results saved with columns: ['news_id', 'speech_id', 'cosine_similarity', 'news_date', 'speech_date', 'days_diff']\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"def load_safe_data():\n    \"\"\"Load data with proper dtype conversions\"\"\"\n    df = pd.read_parquet('news_speech_similarities.parquet').astype({\n        'news_id': 'int64',\n        'speech_id': 'int64',\n        'cosine_similarity': 'float32'  # Convert from float16 to float32\n    })\n    df['news_date'] = pd.to_datetime(df['news_date'])\n    return df\n\n# Load processed data\ndf = load_safe_data()\n\n# Load processed data\ndf = pd.read_parquet('news_speech_similarities.parquet') #We can use this code when we compute everything again, else we have to roead the parquet\n#df = pd.read_parquet(SIMILARITIES_PATH) #Piece of code when we have the path defined, otherwise it'll work by loading them again. \n# Convert to datetime and normalize (remove time components)\ndf['news_date'] = pd.to_datetime(df['news_date']).dt.normalize()\ndf['year'] = df['news_date'].dt.year\n\n# Create daily aggregates with std dev\ndaily_agg = df.groupby('news_date')['cosine_similarity'].agg(['mean', 'std']).reset_index()\ndaily_agg.columns = ['date', 'cosine_similarity', 'std_dev']\n\n# Extend full_dates to include October 2024 explicitly\nend_date = pd.to_datetime('2024-10-31')  # Adjust as needed\nfull_dates = pd.date_range(\n    start=daily_agg['date'].min(), \n    end=end_date, \n    freq='D'\n)\ndaily_agg = daily_agg.set_index('date').reindex(full_dates).reset_index().rename(columns={'index': 'date'})\n\n# Calculate bounds\ndaily_agg['upper_bound'] = daily_agg['cosine_similarity'] + daily_agg['std_dev'].fillna(0)\ndaily_agg['lower_bound'] = daily_agg['cosine_similarity'] - daily_agg['std_dev'].fillna(0)\n\n# Create monthly aggregates (fill NaN with 0 for plotting)\nmonthly_agg = daily_agg.set_index('date').resample('M')['cosine_similarity'].mean().fillna(0).reset_index()\nmonthly_agg['month_label'] = monthly_agg['date'].dt.strftime('%b\\n%Y')\n\n# Get unique years present in data\nyears = daily_agg['date'].dt.year.unique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T13:47:40.589345Z","iopub.execute_input":"2025-03-25T13:47:40.589973Z","iopub.status.idle":"2025-03-25T13:47:45.682895Z","shell.execute_reply.started":"2025-03-25T13:47:40.589939Z","shell.execute_reply":"2025-03-25T13:47:45.681930Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-6-fd48d6189ee0>:39: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n  monthly_agg = daily_agg.set_index('date').resample('M')['cosine_similarity'].mean().fillna(0).reset_index()\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import os\nimport re\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn.functional as F\nimport statsmodels.api as sm\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pathlib import Path\nfrom urllib.parse import urlparse\nfrom sklearn.preprocessing import OneHotEncoder\n\n# Configuration\nEMBEDDINGS_PATH = \"/kaggle/input/embeddings\"\nOUTLET_CACHE = \"outlet_cache.parquet\"\nSIMILARITIES_PATH = \"news_speech_similarities.parquet\"\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T13:47:54.067466Z","iopub.execute_input":"2025-03-25T13:47:54.067854Z","iopub.status.idle":"2025-03-25T13:47:54.072854Z","shell.execute_reply.started":"2025-03-25T13:47:54.067820Z","shell.execute_reply":"2025-03-25T13:47:54.071918Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"import statsmodels.formula.api as smf\nimport statsmodels.formula.api as smf\n\n\ndef extract_and_cache_outlets(news_df, force_refresh=False):\n    \"\"\"Efficient outlet extraction with caching\"\"\"\n    if not force_refresh and Path(OUTLET_CACHE_PATH).exists():\n        # Read the cached outlets as a Series\n        return pd.read_parquet(OUTLET_CACHE_PATH)['outlet']\n    \n    print(\"Extracting outlets...\")\n    pattern = r\"https?://(?:www\\.)?([^/.]+)\\.\"\n    news_df['outlet'] = news_df['Link'].str.extract(pattern, flags=re.IGNORECASE)[0].str.lower()\n    news_df['outlet'] = news_df['outlet'].fillna('unknown')\n    \n    # Save just the outlet series\n    news_df[['outlet']].to_parquet(OUTLET_CACHE_PATH)\n    return news_df['outlet']\n\ndef prepare_regression_data(enriched_df, news_embeddings):\n    \"\"\"Prepare data for regression analyses with caching\"\"\"\n    # Merge outlet information\n    if 'outlet' not in enriched_df.columns:\n        outlets = extract_and_cache_outlets(news_embeddings)\n        # Convert Series to DataFrame with proper column name\n        enriched_df = enriched_df.merge(\n            outlets.rename('outlet').to_frame(),\n            left_on='news_id',\n            right_index=True\n        )\n    \n    # Temporal features\n    enriched_df['date'] = pd.to_datetime(enriched_df['news_date'])\n    enriched_df['year'] = enriched_df['date'].dt.year\n    enriched_df['month'] = enriched_df['date'].dt.month\n    \n    return enriched_df\n\ndef run_combined_regression(df):\n    \"\"\"Run combined temporal + outlet regression\"\"\"\n    # Get top outlets (cached)\n    if not TOP_OUTLET_CACHE.exists():\n        top_outlets = df['outlet'].value_counts().nlargest(10).index.tolist()\n        pd.Series(top_outlets).to_csv(TOP_OUTLET_CACHE, index=False)\n    else:\n        top_outlets = pd.read_csv(TOP_OUTLET_CACHE).squeeze().tolist()\n    \n    # Filter and format\n    df = df[df['outlet'].isin(top_outlets)].copy()\n    df['outlet'] = pd.Categorical(df['outlet'], categories=top_outlets)\n    \n    # Formula specification\n    formula = \"cosine_similarity ~ days_diff + C(outlet) + C(year) + C(month)\"\n    \n    # Fit robust regression\n    model = smf.ols(formula, data=df).fit(\n        cov_type='HC3',\n        use_t=True\n    )\n    \n    return model\n\ndef format_regression_results(model):\n    \"\"\"Create human-readable regression summary\"\"\"\n    results = model.summary2().tables[1]\n    results['Significance'] = results['P>|t|'].apply(\n        lambda x: '***' if x < 0.001 else '**' if x < 0.01 else '*' if x < 0.05 else ''\n    )\n    return results[['Coef.', 'Std.Err.', 'Significance']]\n\nif __name__ == \"__main__\":\n    # Load and prepare data\n    enriched_df = pd.read_parquet('news_speech_similarities.parquet')\n    enriched_df = prepare_regression_data(enriched_df, news_embeddings)\n    \n    # Run combined regression\n    combined_model = run_combined_regression(enriched_df)\n    \n    print(\"=== Combined Regression Results ===\")\n    print(format_regression_results(combined_model))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-25T14:15:17.404220Z","iopub.execute_input":"2025-03-25T14:15:17.404556Z","iopub.status.idle":"2025-03-25T14:18:31.494120Z","shell.execute_reply.started":"2025-03-25T14:15:17.404527Z","shell.execute_reply":"2025-03-25T14:18:31.492985Z"}},"outputs":[{"name":"stdout","text":"=== Combined Regression Results ===\n                              Coef.  Std.Err. Significance\nIntercept                  0.253413  0.000376          ***\nC(outlet)[T.proceso]       0.056428  0.000048          ***\nC(outlet)[T.oem]           0.077872  0.000073          ***\nC(outlet)[T.politica]      0.029216  0.000073          ***\nC(outlet)[T.elfinanciero]  0.019403  0.000079          ***\nC(outlet)[T.forbes]        0.025054  0.000085          ***\nC(outlet)[T.elpais]       -0.005327  0.000089          ***\nC(outlet)[T.eleconomista]  0.060001  0.000097          ***\nC(outlet)[T.lasillarota]   0.080962  0.000096          ***\nC(outlet)[T.milenio]       0.042358  0.000127          ***\nC(year)[T.2019]           -0.003982  0.000375          ***\nC(year)[T.2020]            0.010182  0.000373          ***\nC(year)[T.2021]            0.004434  0.000370          ***\nC(year)[T.2022]            0.015632  0.000369          ***\nC(year)[T.2023]            0.022493  0.000369          ***\nC(year)[T.2024]            0.048130  0.000370          ***\nC(month)[T.2]              0.010841  0.000091          ***\nC(month)[T.3]              0.007760  0.000093          ***\nC(month)[T.4]             -0.007290  0.000098          ***\nC(month)[T.5]             -0.003415  0.000095          ***\nC(month)[T.6]              0.000864  0.000093          ***\nC(month)[T.7]             -0.000689  0.000086          ***\nC(month)[T.8]             -0.007694  0.000089          ***\nC(month)[T.9]              0.008120  0.000090          ***\nC(month)[T.10]             0.007502  0.000101          ***\nC(month)[T.11]             0.008552  0.000102          ***\nC(month)[T.12]             0.017860  0.000104          ***\ndays_diff                 -0.001324  0.000009          ***\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}